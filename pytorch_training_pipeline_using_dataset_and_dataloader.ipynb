{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38930ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b60b637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# link : https://github.com/prashant-kikani/breast-cancer-detection/blob/master/breast-cancer-data.csv\n",
    "df=pd.read_csv(\"breast-cancer-data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fb20cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      " 32  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 146.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e9599a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['id',\"Unnamed: 32\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a447a13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8d69c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c5b9c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(df.iloc[:,1:],df.iloc[:,0],test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75272b58",
   "metadata": {},
   "source": [
    "# Scale the data  to send in NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3abe888",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "x_train=scaler.fit_transform(X_train)\n",
    "x_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39aa1f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.9420495 , -1.67409547, -0.96611872, ..., -1.25795714,\n",
       "        -1.20075062, -0.99507394],\n",
       "       [-0.89385401, -0.13469494, -0.79562993, ...,  2.05536512,\n",
       "         1.94391533,  3.28473875],\n",
       "       [-0.30133302, -0.17508044, -0.27596701, ...,  1.400095  ,\n",
       "         1.54672729,  1.98694798],\n",
       "       ...,\n",
       "       [-1.83508353,  1.221783  , -1.83577544, ..., -1.73798759,\n",
       "        -0.0623534 , -0.76564307],\n",
       "       [ 0.16077666, -0.41264225,  0.12976351, ..., -0.48936737,\n",
       "         1.07760755, -0.62311784],\n",
       "       [-0.2899929 ,  2.05800057, -0.32104818, ..., -0.54196933,\n",
       "        -0.68471892, -1.11094812]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58ed5550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296    B\n",
       "379    M\n",
       "47     M\n",
       "202    M\n",
       "494    B\n",
       "      ..\n",
       "479    M\n",
       "50     B\n",
       "568    B\n",
       "447    B\n",
       "543    B\n",
       "Name: diagnosis, Length: 455, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01701d2b",
   "metadata": {},
   "source": [
    "# Now change label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6488cf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder=LabelEncoder()\n",
    "y_train=encoder.fit_transform(y_train)\n",
    "y_test=encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f8b1a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b8f09f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f1b9fca",
   "metadata": {},
   "source": [
    "# Convert Numpy Array to pytorch tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316c58b9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c656f74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor=torch.from_numpy(x_train).to(torch.float32)\n",
    "x_test_tensor=torch.from_numpy(x_test).to(torch.float32)\n",
    "y_train_tensor=torch.from_numpy(y_train).to(torch.float32).unsqueeze(1)\n",
    "y_test_tensor=torch.from_numpy(y_test).to(torch.float32).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fce86aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([455, 30])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baac569c",
   "metadata": {},
   "source": [
    "# Use Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d1f280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,features,labels):\n",
    "        self.features=features\n",
    "        self.labels=labels\n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "    def __getitem__(self,index):\n",
    "        return self.features[index],self.labels[index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4c8dbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=CustomDataset(x_train_tensor,y_train_tensor)\n",
    "test_dataset=CustomDataset(x_test_tensor,y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "022dcd66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.7597,  0.5661,  1.6838,  1.7828, -0.3579,  0.1457,  0.1042,  0.7049,\n",
       "         -0.6979, -1.0607,  0.5895, -0.5503,  0.6250,  0.6628, -0.2807, -0.3543,\n",
       "         -0.2801,  0.4637, -0.7528, -0.7559,  1.6409,  0.0960,  1.5745,  1.5650,\n",
       "          0.0104, -0.1076, -0.0105,  0.9147, -0.4721, -0.9418]),\n",
       " tensor([1.]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7648ca9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "train_loader=DataLoader(train_dataset,batch_size=32,shuffle=True)\n",
    "test_loader=DataLoader(test_dataset,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c46672a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9d233e1",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa807189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class MyNN(nn.Module):\n",
    "    def __init__(self,features):\n",
    "        super().__init__()\n",
    "        self.network=nn.Sequential(\n",
    "            nn.Linear(features,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.network(x)\n",
    "      \n",
    "\n",
    "   \n",
    "   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e610f736",
   "metadata": {},
   "source": [
    "# Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c09b28f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss = 0.6801\n",
      "Epoch 1, Loss = 0.6794\n",
      "Epoch 1, Loss = 0.6791\n",
      "Epoch 1, Loss = 0.6644\n",
      "Epoch 1, Loss = 0.6680\n",
      "Epoch 1, Loss = 0.6854\n",
      "Epoch 1, Loss = 0.6705\n",
      "Epoch 1, Loss = 0.6532\n",
      "Epoch 1, Loss = 0.6364\n",
      "Epoch 1, Loss = 0.6504\n",
      "Epoch 1, Loss = 0.6766\n",
      "Epoch 1, Loss = 0.6432\n",
      "Epoch 1, Loss = 0.6885\n",
      "Epoch 1, Loss = 0.6289\n",
      "Epoch 1, Loss = 0.6440\n",
      "Epoch 2, Loss = 0.6447\n",
      "Epoch 2, Loss = 0.6444\n",
      "Epoch 2, Loss = 0.6146\n",
      "Epoch 2, Loss = 0.6358\n",
      "Epoch 2, Loss = 0.5870\n",
      "Epoch 2, Loss = 0.6342\n",
      "Epoch 2, Loss = 0.6104\n",
      "Epoch 2, Loss = 0.5976\n",
      "Epoch 2, Loss = 0.6146\n",
      "Epoch 2, Loss = 0.6077\n",
      "Epoch 2, Loss = 0.5979\n",
      "Epoch 2, Loss = 0.5812\n",
      "Epoch 2, Loss = 0.5880\n",
      "Epoch 2, Loss = 0.5896\n",
      "Epoch 2, Loss = 0.5445\n",
      "Epoch 3, Loss = 0.5808\n",
      "Epoch 3, Loss = 0.5785\n",
      "Epoch 3, Loss = 0.5700\n",
      "Epoch 3, Loss = 0.5657\n",
      "Epoch 3, Loss = 0.5703\n",
      "Epoch 3, Loss = 0.5642\n",
      "Epoch 3, Loss = 0.5684\n",
      "Epoch 3, Loss = 0.5616\n",
      "Epoch 3, Loss = 0.5804\n",
      "Epoch 3, Loss = 0.5799\n",
      "Epoch 3, Loss = 0.5743\n",
      "Epoch 3, Loss = 0.5384\n",
      "Epoch 3, Loss = 0.5318\n",
      "Epoch 3, Loss = 0.5313\n",
      "Epoch 3, Loss = 0.4975\n",
      "Epoch 4, Loss = 0.5061\n",
      "Epoch 4, Loss = 0.5788\n",
      "Epoch 4, Loss = 0.5537\n",
      "Epoch 4, Loss = 0.5000\n",
      "Epoch 4, Loss = 0.5488\n",
      "Epoch 4, Loss = 0.5325\n",
      "Epoch 4, Loss = 0.5396\n",
      "Epoch 4, Loss = 0.5191\n",
      "Epoch 4, Loss = 0.5263\n",
      "Epoch 4, Loss = 0.5004\n",
      "Epoch 4, Loss = 0.4956\n",
      "Epoch 4, Loss = 0.5286\n",
      "Epoch 4, Loss = 0.5325\n",
      "Epoch 4, Loss = 0.4594\n",
      "Epoch 4, Loss = 0.4812\n",
      "Epoch 5, Loss = 0.5570\n",
      "Epoch 5, Loss = 0.4920\n",
      "Epoch 5, Loss = 0.5029\n",
      "Epoch 5, Loss = 0.5256\n",
      "Epoch 5, Loss = 0.4630\n",
      "Epoch 5, Loss = 0.4769\n",
      "Epoch 5, Loss = 0.4810\n",
      "Epoch 5, Loss = 0.4614\n",
      "Epoch 5, Loss = 0.4722\n",
      "Epoch 5, Loss = 0.4432\n",
      "Epoch 5, Loss = 0.5004\n",
      "Epoch 5, Loss = 0.4700\n",
      "Epoch 5, Loss = 0.4753\n",
      "Epoch 5, Loss = 0.4748\n",
      "Epoch 5, Loss = 0.5183\n",
      "Epoch 6, Loss = 0.4405\n",
      "Epoch 6, Loss = 0.4690\n",
      "Epoch 6, Loss = 0.4253\n",
      "Epoch 6, Loss = 0.4901\n",
      "Epoch 6, Loss = 0.4798\n",
      "Epoch 6, Loss = 0.4805\n",
      "Epoch 6, Loss = 0.4503\n",
      "Epoch 6, Loss = 0.4356\n",
      "Epoch 6, Loss = 0.4151\n",
      "Epoch 6, Loss = 0.4121\n",
      "Epoch 6, Loss = 0.4758\n",
      "Epoch 6, Loss = 0.4836\n",
      "Epoch 6, Loss = 0.4257\n",
      "Epoch 6, Loss = 0.4668\n",
      "Epoch 6, Loss = 0.4515\n",
      "Epoch 7, Loss = 0.4248\n",
      "Epoch 7, Loss = 0.4192\n",
      "Epoch 7, Loss = 0.4448\n",
      "Epoch 7, Loss = 0.4160\n",
      "Epoch 7, Loss = 0.4010\n",
      "Epoch 7, Loss = 0.4532\n",
      "Epoch 7, Loss = 0.4519\n",
      "Epoch 7, Loss = 0.3857\n",
      "Epoch 7, Loss = 0.4045\n",
      "Epoch 7, Loss = 0.4514\n",
      "Epoch 7, Loss = 0.4177\n",
      "Epoch 7, Loss = 0.4650\n",
      "Epoch 7, Loss = 0.4369\n",
      "Epoch 7, Loss = 0.3767\n",
      "Epoch 7, Loss = 0.3906\n",
      "Epoch 8, Loss = 0.4185\n",
      "Epoch 8, Loss = 0.3901\n",
      "Epoch 8, Loss = 0.4012\n",
      "Epoch 8, Loss = 0.3509\n",
      "Epoch 8, Loss = 0.4064\n",
      "Epoch 8, Loss = 0.3385\n",
      "Epoch 8, Loss = 0.3973\n",
      "Epoch 8, Loss = 0.4255\n",
      "Epoch 8, Loss = 0.3883\n",
      "Epoch 8, Loss = 0.4419\n",
      "Epoch 8, Loss = 0.4618\n",
      "Epoch 8, Loss = 0.4167\n",
      "Epoch 8, Loss = 0.4072\n",
      "Epoch 8, Loss = 0.3539\n",
      "Epoch 8, Loss = 0.2647\n",
      "Epoch 9, Loss = 0.3528\n",
      "Epoch 9, Loss = 0.3567\n",
      "Epoch 9, Loss = 0.4119\n",
      "Epoch 9, Loss = 0.4076\n",
      "Epoch 9, Loss = 0.3586\n",
      "Epoch 9, Loss = 0.3531\n",
      "Epoch 9, Loss = 0.4586\n",
      "Epoch 9, Loss = 0.4097\n",
      "Epoch 9, Loss = 0.3930\n",
      "Epoch 9, Loss = 0.3038\n",
      "Epoch 9, Loss = 0.3428\n",
      "Epoch 9, Loss = 0.3490\n",
      "Epoch 9, Loss = 0.3777\n",
      "Epoch 9, Loss = 0.3815\n",
      "Epoch 9, Loss = 0.2850\n",
      "Epoch 10, Loss = 0.3094\n",
      "Epoch 10, Loss = 0.3192\n",
      "Epoch 10, Loss = 0.2984\n",
      "Epoch 10, Loss = 0.3521\n",
      "Epoch 10, Loss = 0.3958\n",
      "Epoch 10, Loss = 0.3895\n",
      "Epoch 10, Loss = 0.3556\n",
      "Epoch 10, Loss = 0.3593\n",
      "Epoch 10, Loss = 0.3352\n",
      "Epoch 10, Loss = 0.3348\n",
      "Epoch 10, Loss = 0.3120\n",
      "Epoch 10, Loss = 0.3866\n",
      "Epoch 10, Loss = 0.4189\n",
      "Epoch 10, Loss = 0.3821\n",
      "Epoch 10, Loss = 0.3026\n",
      "Epoch 11, Loss = 0.3291\n",
      "Epoch 11, Loss = 0.3092\n",
      "Epoch 11, Loss = 0.2707\n",
      "Epoch 11, Loss = 0.3595\n",
      "Epoch 11, Loss = 0.3842\n",
      "Epoch 11, Loss = 0.2794\n",
      "Epoch 11, Loss = 0.3672\n",
      "Epoch 11, Loss = 0.3336\n",
      "Epoch 11, Loss = 0.2859\n",
      "Epoch 11, Loss = 0.3070\n",
      "Epoch 11, Loss = 0.4386\n",
      "Epoch 11, Loss = 0.3028\n",
      "Epoch 11, Loss = 0.3669\n",
      "Epoch 11, Loss = 0.3144\n",
      "Epoch 11, Loss = 0.4432\n",
      "Epoch 12, Loss = 0.2948\n",
      "Epoch 12, Loss = 0.3647\n",
      "Epoch 12, Loss = 0.3406\n",
      "Epoch 12, Loss = 0.2973\n",
      "Epoch 12, Loss = 0.3140\n",
      "Epoch 12, Loss = 0.2669\n",
      "Epoch 12, Loss = 0.3053\n",
      "Epoch 12, Loss = 0.3303\n",
      "Epoch 12, Loss = 0.4205\n",
      "Epoch 12, Loss = 0.3308\n",
      "Epoch 12, Loss = 0.3299\n",
      "Epoch 12, Loss = 0.3456\n",
      "Epoch 12, Loss = 0.2214\n",
      "Epoch 12, Loss = 0.2592\n",
      "Epoch 12, Loss = 0.3691\n",
      "Epoch 13, Loss = 0.3223\n",
      "Epoch 13, Loss = 0.3078\n",
      "Epoch 13, Loss = 0.2908\n",
      "Epoch 13, Loss = 0.2249\n",
      "Epoch 13, Loss = 0.2667\n",
      "Epoch 13, Loss = 0.3988\n",
      "Epoch 13, Loss = 0.3485\n",
      "Epoch 13, Loss = 0.3567\n",
      "Epoch 13, Loss = 0.2815\n",
      "Epoch 13, Loss = 0.3027\n",
      "Epoch 13, Loss = 0.2770\n",
      "Epoch 13, Loss = 0.3132\n",
      "Epoch 13, Loss = 0.2748\n",
      "Epoch 13, Loss = 0.2453\n",
      "Epoch 13, Loss = 0.3324\n",
      "Epoch 14, Loss = 0.3494\n",
      "Epoch 14, Loss = 0.2210\n",
      "Epoch 14, Loss = 0.3270\n",
      "Epoch 14, Loss = 0.3457\n",
      "Epoch 14, Loss = 0.2387\n",
      "Epoch 14, Loss = 0.3104\n",
      "Epoch 14, Loss = 0.2501\n",
      "Epoch 14, Loss = 0.2842\n",
      "Epoch 14, Loss = 0.3408\n",
      "Epoch 14, Loss = 0.2556\n",
      "Epoch 14, Loss = 0.2677\n",
      "Epoch 14, Loss = 0.2299\n",
      "Epoch 14, Loss = 0.2609\n",
      "Epoch 14, Loss = 0.3613\n",
      "Epoch 14, Loss = 0.1987\n",
      "Epoch 15, Loss = 0.2953\n",
      "Epoch 15, Loss = 0.2399\n",
      "Epoch 15, Loss = 0.2542\n",
      "Epoch 15, Loss = 0.2276\n",
      "Epoch 15, Loss = 0.2449\n",
      "Epoch 15, Loss = 0.3656\n",
      "Epoch 15, Loss = 0.2404\n",
      "Epoch 15, Loss = 0.2989\n",
      "Epoch 15, Loss = 0.2523\n",
      "Epoch 15, Loss = 0.2437\n",
      "Epoch 15, Loss = 0.3283\n",
      "Epoch 15, Loss = 0.3255\n",
      "Epoch 15, Loss = 0.2876\n",
      "Epoch 15, Loss = 0.2387\n",
      "Epoch 15, Loss = 0.2849\n",
      "Epoch 16, Loss = 0.2514\n",
      "Epoch 16, Loss = 0.2732\n",
      "Epoch 16, Loss = 0.3323\n",
      "Epoch 16, Loss = 0.2519\n",
      "Epoch 16, Loss = 0.2741\n",
      "Epoch 16, Loss = 0.2378\n",
      "Epoch 16, Loss = 0.2570\n",
      "Epoch 16, Loss = 0.2971\n",
      "Epoch 16, Loss = 0.2267\n",
      "Epoch 16, Loss = 0.2889\n",
      "Epoch 16, Loss = 0.2025\n",
      "Epoch 16, Loss = 0.2773\n",
      "Epoch 16, Loss = 0.2808\n",
      "Epoch 16, Loss = 0.2598\n",
      "Epoch 16, Loss = 0.1478\n",
      "Epoch 17, Loss = 0.2659\n",
      "Epoch 17, Loss = 0.2013\n",
      "Epoch 17, Loss = 0.3089\n",
      "Epoch 17, Loss = 0.2602\n",
      "Epoch 17, Loss = 0.2448\n",
      "Epoch 17, Loss = 0.3245\n",
      "Epoch 17, Loss = 0.1588\n",
      "Epoch 17, Loss = 0.2015\n",
      "Epoch 17, Loss = 0.2376\n",
      "Epoch 17, Loss = 0.2953\n",
      "Epoch 17, Loss = 0.3455\n",
      "Epoch 17, Loss = 0.2709\n",
      "Epoch 17, Loss = 0.1977\n",
      "Epoch 17, Loss = 0.2123\n",
      "Epoch 17, Loss = 0.3110\n",
      "Epoch 18, Loss = 0.2595\n",
      "Epoch 18, Loss = 0.2084\n",
      "Epoch 18, Loss = 0.2881\n",
      "Epoch 18, Loss = 0.2339\n",
      "Epoch 18, Loss = 0.2304\n",
      "Epoch 18, Loss = 0.2890\n",
      "Epoch 18, Loss = 0.1930\n",
      "Epoch 18, Loss = 0.3370\n",
      "Epoch 18, Loss = 0.2419\n",
      "Epoch 18, Loss = 0.2357\n",
      "Epoch 18, Loss = 0.2594\n",
      "Epoch 18, Loss = 0.1947\n",
      "Epoch 18, Loss = 0.1780\n",
      "Epoch 18, Loss = 0.1850\n",
      "Epoch 18, Loss = 0.5702\n",
      "Epoch 19, Loss = 0.2537\n",
      "Epoch 19, Loss = 0.2465\n",
      "Epoch 19, Loss = 0.2456\n",
      "Epoch 19, Loss = 0.1694\n",
      "Epoch 19, Loss = 0.1794\n",
      "Epoch 19, Loss = 0.2325\n",
      "Epoch 19, Loss = 0.1903\n",
      "Epoch 19, Loss = 0.2547\n",
      "Epoch 19, Loss = 0.2527\n",
      "Epoch 19, Loss = 0.2730\n",
      "Epoch 19, Loss = 0.1911\n",
      "Epoch 19, Loss = 0.2270\n",
      "Epoch 19, Loss = 0.1958\n",
      "Epoch 19, Loss = 0.3841\n",
      "Epoch 19, Loss = 0.1902\n",
      "Epoch 20, Loss = 0.1902\n",
      "Epoch 20, Loss = 0.2296\n",
      "Epoch 20, Loss = 0.2057\n",
      "Epoch 20, Loss = 0.2373\n",
      "Epoch 20, Loss = 0.2864\n",
      "Epoch 20, Loss = 0.2009\n",
      "Epoch 20, Loss = 0.2145\n",
      "Epoch 20, Loss = 0.2621\n",
      "Epoch 20, Loss = 0.2517\n",
      "Epoch 20, Loss = 0.1512\n",
      "Epoch 20, Loss = 0.1949\n",
      "Epoch 20, Loss = 0.2783\n",
      "Epoch 20, Loss = 0.2548\n",
      "Epoch 20, Loss = 0.1989\n",
      "Epoch 20, Loss = 0.2909\n",
      "Epoch 21, Loss = 0.2346\n",
      "Epoch 21, Loss = 0.2615\n",
      "Epoch 21, Loss = 0.2096\n",
      "Epoch 21, Loss = 0.2126\n",
      "Epoch 21, Loss = 0.1506\n",
      "Epoch 21, Loss = 0.2116\n",
      "Epoch 21, Loss = 0.2644\n",
      "Epoch 21, Loss = 0.2960\n",
      "Epoch 21, Loss = 0.2100\n",
      "Epoch 21, Loss = 0.1714\n",
      "Epoch 21, Loss = 0.2844\n",
      "Epoch 21, Loss = 0.1586\n",
      "Epoch 21, Loss = 0.2372\n",
      "Epoch 21, Loss = 0.1796\n",
      "Epoch 21, Loss = 0.1421\n",
      "Epoch 22, Loss = 0.1512\n",
      "Epoch 22, Loss = 0.2004\n",
      "Epoch 22, Loss = 0.2337\n",
      "Epoch 22, Loss = 0.2004\n",
      "Epoch 22, Loss = 0.2823\n",
      "Epoch 22, Loss = 0.2318\n",
      "Epoch 22, Loss = 0.1778\n",
      "Epoch 22, Loss = 0.2048\n",
      "Epoch 22, Loss = 0.2071\n",
      "Epoch 22, Loss = 0.1832\n",
      "Epoch 22, Loss = 0.2445\n",
      "Epoch 22, Loss = 0.2755\n",
      "Epoch 22, Loss = 0.2289\n",
      "Epoch 22, Loss = 0.1650\n",
      "Epoch 22, Loss = 0.1227\n",
      "Epoch 23, Loss = 0.2269\n",
      "Epoch 23, Loss = 0.2880\n",
      "Epoch 23, Loss = 0.1624\n",
      "Epoch 23, Loss = 0.1711\n",
      "Epoch 23, Loss = 0.1605\n",
      "Epoch 23, Loss = 0.2070\n",
      "Epoch 23, Loss = 0.2147\n",
      "Epoch 23, Loss = 0.2666\n",
      "Epoch 23, Loss = 0.1907\n",
      "Epoch 23, Loss = 0.2111\n",
      "Epoch 23, Loss = 0.2309\n",
      "Epoch 23, Loss = 0.2003\n",
      "Epoch 23, Loss = 0.2868\n",
      "Epoch 23, Loss = 0.0913\n",
      "Epoch 23, Loss = 0.0662\n",
      "Epoch 24, Loss = 0.1467\n",
      "Epoch 24, Loss = 0.2248\n",
      "Epoch 24, Loss = 0.2040\n",
      "Epoch 24, Loss = 0.1831\n",
      "Epoch 24, Loss = 0.1660\n",
      "Epoch 24, Loss = 0.2152\n",
      "Epoch 24, Loss = 0.1674\n",
      "Epoch 24, Loss = 0.1747\n",
      "Epoch 24, Loss = 0.1740\n",
      "Epoch 24, Loss = 0.3054\n",
      "Epoch 24, Loss = 0.2044\n",
      "Epoch 24, Loss = 0.1373\n",
      "Epoch 24, Loss = 0.3397\n",
      "Epoch 24, Loss = 0.1685\n",
      "Epoch 24, Loss = 0.1272\n",
      "Epoch 25, Loss = 0.2289\n",
      "Epoch 25, Loss = 0.2169\n",
      "Epoch 25, Loss = 0.3272\n",
      "Epoch 25, Loss = 0.1732\n",
      "Epoch 25, Loss = 0.1871\n",
      "Epoch 25, Loss = 0.2609\n",
      "Epoch 25, Loss = 0.1392\n",
      "Epoch 25, Loss = 0.1752\n",
      "Epoch 25, Loss = 0.1247\n",
      "Epoch 25, Loss = 0.1839\n",
      "Epoch 25, Loss = 0.1836\n",
      "Epoch 25, Loss = 0.2032\n",
      "Epoch 25, Loss = 0.2011\n",
      "Epoch 25, Loss = 0.1365\n",
      "Epoch 25, Loss = 0.0821\n",
      "Epoch 26, Loss = 0.1496\n",
      "Epoch 26, Loss = 0.1650\n",
      "Epoch 26, Loss = 0.1592\n",
      "Epoch 26, Loss = 0.2147\n",
      "Epoch 26, Loss = 0.2461\n",
      "Epoch 26, Loss = 0.2188\n",
      "Epoch 26, Loss = 0.1250\n",
      "Epoch 26, Loss = 0.1243\n",
      "Epoch 26, Loss = 0.2112\n",
      "Epoch 26, Loss = 0.1817\n",
      "Epoch 26, Loss = 0.3175\n",
      "Epoch 26, Loss = 0.1826\n",
      "Epoch 26, Loss = 0.1483\n",
      "Epoch 26, Loss = 0.2147\n",
      "Epoch 26, Loss = 0.1253\n",
      "Epoch 27, Loss = 0.2678\n",
      "Epoch 27, Loss = 0.1814\n",
      "Epoch 27, Loss = 0.1629\n",
      "Epoch 27, Loss = 0.1438\n",
      "Epoch 27, Loss = 0.1342\n",
      "Epoch 27, Loss = 0.1364\n",
      "Epoch 27, Loss = 0.1295\n",
      "Epoch 27, Loss = 0.2070\n",
      "Epoch 27, Loss = 0.2199\n",
      "Epoch 27, Loss = 0.2781\n",
      "Epoch 27, Loss = 0.1712\n",
      "Epoch 27, Loss = 0.1644\n",
      "Epoch 27, Loss = 0.1807\n",
      "Epoch 27, Loss = 0.2237\n",
      "Epoch 27, Loss = 0.0698\n",
      "Epoch 28, Loss = 0.1878\n",
      "Epoch 28, Loss = 0.1419\n",
      "Epoch 28, Loss = 0.1878\n",
      "Epoch 28, Loss = 0.1805\n",
      "Epoch 28, Loss = 0.1896\n",
      "Epoch 28, Loss = 0.1966\n",
      "Epoch 28, Loss = 0.1652\n",
      "Epoch 28, Loss = 0.1489\n",
      "Epoch 28, Loss = 0.1607\n",
      "Epoch 28, Loss = 0.1961\n",
      "Epoch 28, Loss = 0.1661\n",
      "Epoch 28, Loss = 0.2496\n",
      "Epoch 28, Loss = 0.1968\n",
      "Epoch 28, Loss = 0.1546\n",
      "Epoch 28, Loss = 0.1355\n",
      "Epoch 29, Loss = 0.1028\n",
      "Epoch 29, Loss = 0.1142\n",
      "Epoch 29, Loss = 0.1563\n",
      "Epoch 29, Loss = 0.1581\n",
      "Epoch 29, Loss = 0.1864\n",
      "Epoch 29, Loss = 0.1401\n",
      "Epoch 29, Loss = 0.1721\n",
      "Epoch 29, Loss = 0.2455\n",
      "Epoch 29, Loss = 0.2694\n",
      "Epoch 29, Loss = 0.2276\n",
      "Epoch 29, Loss = 0.1643\n",
      "Epoch 29, Loss = 0.1843\n",
      "Epoch 29, Loss = 0.1968\n",
      "Epoch 29, Loss = 0.1443\n",
      "Epoch 29, Loss = 0.1243\n",
      "Epoch 30, Loss = 0.1218\n",
      "Epoch 30, Loss = 0.1443\n",
      "Epoch 30, Loss = 0.1649\n",
      "Epoch 30, Loss = 0.1446\n",
      "Epoch 30, Loss = 0.1234\n",
      "Epoch 30, Loss = 0.2002\n",
      "Epoch 30, Loss = 0.1682\n",
      "Epoch 30, Loss = 0.1902\n",
      "Epoch 30, Loss = 0.2014\n",
      "Epoch 30, Loss = 0.1504\n",
      "Epoch 30, Loss = 0.1809\n",
      "Epoch 30, Loss = 0.1805\n",
      "Epoch 30, Loss = 0.1873\n",
      "Epoch 30, Loss = 0.1991\n",
      "Epoch 30, Loss = 0.3338\n",
      "Epoch 31, Loss = 0.2041\n",
      "Epoch 31, Loss = 0.1134\n",
      "Epoch 31, Loss = 0.1520\n",
      "Epoch 31, Loss = 0.1781\n",
      "Epoch 31, Loss = 0.3041\n",
      "Epoch 31, Loss = 0.1122\n",
      "Epoch 31, Loss = 0.1131\n",
      "Epoch 31, Loss = 0.0956\n",
      "Epoch 31, Loss = 0.1709\n",
      "Epoch 31, Loss = 0.2112\n",
      "Epoch 31, Loss = 0.2311\n",
      "Epoch 31, Loss = 0.1763\n",
      "Epoch 31, Loss = 0.1884\n",
      "Epoch 31, Loss = 0.1155\n",
      "Epoch 31, Loss = 0.0604\n",
      "Epoch 32, Loss = 0.1364\n",
      "Epoch 32, Loss = 0.1014\n",
      "Epoch 32, Loss = 0.2164\n",
      "Epoch 32, Loss = 0.1226\n",
      "Epoch 32, Loss = 0.1385\n",
      "Epoch 32, Loss = 0.1548\n",
      "Epoch 32, Loss = 0.1831\n",
      "Epoch 32, Loss = 0.1647\n",
      "Epoch 32, Loss = 0.1365\n",
      "Epoch 32, Loss = 0.1727\n",
      "Epoch 32, Loss = 0.2525\n",
      "Epoch 32, Loss = 0.0823\n",
      "Epoch 32, Loss = 0.1629\n",
      "Epoch 32, Loss = 0.2817\n",
      "Epoch 32, Loss = 0.0990\n",
      "Epoch 33, Loss = 0.1558\n",
      "Epoch 33, Loss = 0.2024\n",
      "Epoch 33, Loss = 0.1539\n",
      "Epoch 33, Loss = 0.1609\n",
      "Epoch 33, Loss = 0.1131\n",
      "Epoch 33, Loss = 0.1506\n",
      "Epoch 33, Loss = 0.1506\n",
      "Epoch 33, Loss = 0.1092\n",
      "Epoch 33, Loss = 0.2006\n",
      "Epoch 33, Loss = 0.1654\n",
      "Epoch 33, Loss = 0.1890\n",
      "Epoch 33, Loss = 0.1217\n",
      "Epoch 33, Loss = 0.1833\n",
      "Epoch 33, Loss = 0.2010\n",
      "Epoch 33, Loss = 0.0915\n",
      "Epoch 34, Loss = 0.1971\n",
      "Epoch 34, Loss = 0.1472\n",
      "Epoch 34, Loss = 0.0615\n",
      "Epoch 34, Loss = 0.2467\n",
      "Epoch 34, Loss = 0.1813\n",
      "Epoch 34, Loss = 0.1943\n",
      "Epoch 34, Loss = 0.2805\n",
      "Epoch 34, Loss = 0.1209\n",
      "Epoch 34, Loss = 0.0867\n",
      "Epoch 34, Loss = 0.1237\n",
      "Epoch 34, Loss = 0.1525\n",
      "Epoch 34, Loss = 0.1826\n",
      "Epoch 34, Loss = 0.1147\n",
      "Epoch 34, Loss = 0.1084\n",
      "Epoch 34, Loss = 0.1571\n",
      "Epoch 35, Loss = 0.0959\n",
      "Epoch 35, Loss = 0.1462\n",
      "Epoch 35, Loss = 0.0937\n",
      "Epoch 35, Loss = 0.1477\n",
      "Epoch 35, Loss = 0.1983\n",
      "Epoch 35, Loss = 0.1274\n",
      "Epoch 35, Loss = 0.2510\n",
      "Epoch 35, Loss = 0.1004\n",
      "Epoch 35, Loss = 0.1291\n",
      "Epoch 35, Loss = 0.1665\n",
      "Epoch 35, Loss = 0.2335\n",
      "Epoch 35, Loss = 0.1681\n",
      "Epoch 35, Loss = 0.1588\n",
      "Epoch 35, Loss = 0.1620\n",
      "Epoch 35, Loss = 0.0396\n",
      "Epoch 36, Loss = 0.2413\n",
      "Epoch 36, Loss = 0.1449\n",
      "Epoch 36, Loss = 0.1644\n",
      "Epoch 36, Loss = 0.0824\n",
      "Epoch 36, Loss = 0.1188\n",
      "Epoch 36, Loss = 0.1459\n",
      "Epoch 36, Loss = 0.2122\n",
      "Epoch 36, Loss = 0.1360\n",
      "Epoch 36, Loss = 0.0941\n",
      "Epoch 36, Loss = 0.1345\n",
      "Epoch 36, Loss = 0.1091\n",
      "Epoch 36, Loss = 0.1781\n",
      "Epoch 36, Loss = 0.1328\n",
      "Epoch 36, Loss = 0.2188\n",
      "Epoch 36, Loss = 0.1514\n",
      "Epoch 37, Loss = 0.1321\n",
      "Epoch 37, Loss = 0.1175\n",
      "Epoch 37, Loss = 0.1896\n",
      "Epoch 37, Loss = 0.1963\n",
      "Epoch 37, Loss = 0.1778\n",
      "Epoch 37, Loss = 0.0592\n",
      "Epoch 37, Loss = 0.1293\n",
      "Epoch 37, Loss = 0.1627\n",
      "Epoch 37, Loss = 0.2337\n",
      "Epoch 37, Loss = 0.1357\n",
      "Epoch 37, Loss = 0.0749\n",
      "Epoch 37, Loss = 0.1211\n",
      "Epoch 37, Loss = 0.2263\n",
      "Epoch 37, Loss = 0.1409\n",
      "Epoch 37, Loss = 0.0432\n",
      "Epoch 38, Loss = 0.0860\n",
      "Epoch 38, Loss = 0.0824\n",
      "Epoch 38, Loss = 0.1146\n",
      "Epoch 38, Loss = 0.1566\n",
      "Epoch 38, Loss = 0.1667\n",
      "Epoch 38, Loss = 0.1811\n",
      "Epoch 38, Loss = 0.1481\n",
      "Epoch 38, Loss = 0.1025\n",
      "Epoch 38, Loss = 0.2403\n",
      "Epoch 38, Loss = 0.1357\n",
      "Epoch 38, Loss = 0.1814\n",
      "Epoch 38, Loss = 0.1688\n",
      "Epoch 38, Loss = 0.2028\n",
      "Epoch 38, Loss = 0.0893\n",
      "Epoch 38, Loss = 0.0575\n",
      "Epoch 39, Loss = 0.1218\n",
      "Epoch 39, Loss = 0.1474\n",
      "Epoch 39, Loss = 0.1417\n",
      "Epoch 39, Loss = 0.2563\n",
      "Epoch 39, Loss = 0.1234\n",
      "Epoch 39, Loss = 0.0879\n",
      "Epoch 39, Loss = 0.1086\n",
      "Epoch 39, Loss = 0.1076\n",
      "Epoch 39, Loss = 0.2121\n",
      "Epoch 39, Loss = 0.0725\n",
      "Epoch 39, Loss = 0.1507\n",
      "Epoch 39, Loss = 0.1554\n",
      "Epoch 39, Loss = 0.0788\n",
      "Epoch 39, Loss = 0.1829\n",
      "Epoch 39, Loss = 0.3888\n",
      "Epoch 40, Loss = 0.0991\n",
      "Epoch 40, Loss = 0.1086\n",
      "Epoch 40, Loss = 0.1828\n",
      "Epoch 40, Loss = 0.1751\n",
      "Epoch 40, Loss = 0.1296\n",
      "Epoch 40, Loss = 0.1199\n",
      "Epoch 40, Loss = 0.2369\n",
      "Epoch 40, Loss = 0.0517\n",
      "Epoch 40, Loss = 0.0873\n",
      "Epoch 40, Loss = 0.2407\n",
      "Epoch 40, Loss = 0.1275\n",
      "Epoch 40, Loss = 0.1105\n",
      "Epoch 40, Loss = 0.1866\n",
      "Epoch 40, Loss = 0.1222\n",
      "Epoch 40, Loss = 0.0815\n",
      "Epoch 41, Loss = 0.1497\n",
      "Epoch 41, Loss = 0.1243\n",
      "Epoch 41, Loss = 0.2512\n",
      "Epoch 41, Loss = 0.1053\n",
      "Epoch 41, Loss = 0.1400\n",
      "Epoch 41, Loss = 0.0987\n",
      "Epoch 41, Loss = 0.1360\n",
      "Epoch 41, Loss = 0.1440\n",
      "Epoch 41, Loss = 0.0960\n",
      "Epoch 41, Loss = 0.2235\n",
      "Epoch 41, Loss = 0.1229\n",
      "Epoch 41, Loss = 0.0985\n",
      "Epoch 41, Loss = 0.1760\n",
      "Epoch 41, Loss = 0.0661\n",
      "Epoch 41, Loss = 0.1404\n",
      "Epoch 42, Loss = 0.2099\n",
      "Epoch 42, Loss = 0.2296\n",
      "Epoch 42, Loss = 0.1117\n",
      "Epoch 42, Loss = 0.0495\n",
      "Epoch 42, Loss = 0.0845\n",
      "Epoch 42, Loss = 0.1039\n",
      "Epoch 42, Loss = 0.0779\n",
      "Epoch 42, Loss = 0.1451\n",
      "Epoch 42, Loss = 0.1387\n",
      "Epoch 42, Loss = 0.1394\n",
      "Epoch 42, Loss = 0.1549\n",
      "Epoch 42, Loss = 0.1516\n",
      "Epoch 42, Loss = 0.0833\n",
      "Epoch 42, Loss = 0.1869\n",
      "Epoch 42, Loss = 0.2912\n",
      "Epoch 43, Loss = 0.0968\n",
      "Epoch 43, Loss = 0.0957\n",
      "Epoch 43, Loss = 0.2890\n",
      "Epoch 43, Loss = 0.1143\n",
      "Epoch 43, Loss = 0.1534\n",
      "Epoch 43, Loss = 0.1039\n",
      "Epoch 43, Loss = 0.2029\n",
      "Epoch 43, Loss = 0.1181\n",
      "Epoch 43, Loss = 0.1768\n",
      "Epoch 43, Loss = 0.0946\n",
      "Epoch 43, Loss = 0.0993\n",
      "Epoch 43, Loss = 0.1359\n",
      "Epoch 43, Loss = 0.0656\n",
      "Epoch 43, Loss = 0.1209\n",
      "Epoch 43, Loss = 0.1478\n",
      "Epoch 44, Loss = 0.0897\n",
      "Epoch 44, Loss = 0.2226\n",
      "Epoch 44, Loss = 0.1343\n",
      "Epoch 44, Loss = 0.1007\n",
      "Epoch 44, Loss = 0.2091\n",
      "Epoch 44, Loss = 0.1559\n",
      "Epoch 44, Loss = 0.1219\n",
      "Epoch 44, Loss = 0.1155\n",
      "Epoch 44, Loss = 0.1366\n",
      "Epoch 44, Loss = 0.1145\n",
      "Epoch 44, Loss = 0.0913\n",
      "Epoch 44, Loss = 0.1127\n",
      "Epoch 44, Loss = 0.1186\n",
      "Epoch 44, Loss = 0.1312\n",
      "Epoch 44, Loss = 0.0723\n",
      "Epoch 45, Loss = 0.1008\n",
      "Epoch 45, Loss = 0.1056\n",
      "Epoch 45, Loss = 0.0741\n",
      "Epoch 45, Loss = 0.2281\n",
      "Epoch 45, Loss = 0.2360\n",
      "Epoch 45, Loss = 0.0674\n",
      "Epoch 45, Loss = 0.0668\n",
      "Epoch 45, Loss = 0.1580\n",
      "Epoch 45, Loss = 0.1293\n",
      "Epoch 45, Loss = 0.0961\n",
      "Epoch 45, Loss = 0.1882\n",
      "Epoch 45, Loss = 0.1070\n",
      "Epoch 45, Loss = 0.1238\n",
      "Epoch 45, Loss = 0.1432\n",
      "Epoch 45, Loss = 0.0819\n",
      "Epoch 46, Loss = 0.0963\n",
      "Epoch 46, Loss = 0.1101\n",
      "Epoch 46, Loss = 0.1121\n",
      "Epoch 46, Loss = 0.1069\n",
      "Epoch 46, Loss = 0.1312\n",
      "Epoch 46, Loss = 0.1645\n",
      "Epoch 46, Loss = 0.1201\n",
      "Epoch 46, Loss = 0.1153\n",
      "Epoch 46, Loss = 0.1148\n",
      "Epoch 46, Loss = 0.0977\n",
      "Epoch 46, Loss = 0.1894\n",
      "Epoch 46, Loss = 0.0768\n",
      "Epoch 46, Loss = 0.1015\n",
      "Epoch 46, Loss = 0.2421\n",
      "Epoch 46, Loss = 0.1646\n",
      "Epoch 47, Loss = 0.2216\n",
      "Epoch 47, Loss = 0.1109\n",
      "Epoch 47, Loss = 0.2175\n",
      "Epoch 47, Loss = 0.0973\n",
      "Epoch 47, Loss = 0.1046\n",
      "Epoch 47, Loss = 0.1150\n",
      "Epoch 47, Loss = 0.0942\n",
      "Epoch 47, Loss = 0.0822\n",
      "Epoch 47, Loss = 0.0622\n",
      "Epoch 47, Loss = 0.1361\n",
      "Epoch 47, Loss = 0.0775\n",
      "Epoch 47, Loss = 0.1866\n",
      "Epoch 47, Loss = 0.1162\n",
      "Epoch 47, Loss = 0.1437\n",
      "Epoch 47, Loss = 0.1048\n",
      "Epoch 48, Loss = 0.0887\n",
      "Epoch 48, Loss = 0.1414\n",
      "Epoch 48, Loss = 0.0796\n",
      "Epoch 48, Loss = 0.1169\n",
      "Epoch 48, Loss = 0.0960\n",
      "Epoch 48, Loss = 0.1737\n",
      "Epoch 48, Loss = 0.1241\n",
      "Epoch 48, Loss = 0.1093\n",
      "Epoch 48, Loss = 0.1264\n",
      "Epoch 48, Loss = 0.2227\n",
      "Epoch 48, Loss = 0.1209\n",
      "Epoch 48, Loss = 0.1525\n",
      "Epoch 48, Loss = 0.0998\n",
      "Epoch 48, Loss = 0.0881\n",
      "Epoch 48, Loss = 0.1038\n",
      "Epoch 49, Loss = 0.1231\n",
      "Epoch 49, Loss = 0.2103\n",
      "Epoch 49, Loss = 0.1003\n",
      "Epoch 49, Loss = 0.1130\n",
      "Epoch 49, Loss = 0.1104\n",
      "Epoch 49, Loss = 0.1171\n",
      "Epoch 49, Loss = 0.1585\n",
      "Epoch 49, Loss = 0.1215\n",
      "Epoch 49, Loss = 0.0944\n",
      "Epoch 49, Loss = 0.0980\n",
      "Epoch 49, Loss = 0.0717\n",
      "Epoch 49, Loss = 0.1305\n",
      "Epoch 49, Loss = 0.1560\n",
      "Epoch 49, Loss = 0.1259\n",
      "Epoch 49, Loss = 0.0411\n",
      "Epoch 50, Loss = 0.1284\n",
      "Epoch 50, Loss = 0.1410\n",
      "Epoch 50, Loss = 0.1739\n",
      "Epoch 50, Loss = 0.1187\n",
      "Epoch 50, Loss = 0.1150\n",
      "Epoch 50, Loss = 0.1005\n",
      "Epoch 50, Loss = 0.1721\n",
      "Epoch 50, Loss = 0.0917\n",
      "Epoch 50, Loss = 0.1126\n",
      "Epoch 50, Loss = 0.0553\n",
      "Epoch 50, Loss = 0.0583\n",
      "Epoch 50, Loss = 0.1568\n",
      "Epoch 50, Loss = 0.1618\n",
      "Epoch 50, Loss = 0.1251\n",
      "Epoch 50, Loss = 0.0247\n"
     ]
    }
   ],
   "source": [
    "model = MyNN(x_train_tensor.shape[1])\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optim=torch.optim.SGD(model.parameters(),lr=0.01)\n",
    "\n",
    "epochs=50\n",
    "for epoch in range(epochs):\n",
    "    for feature,labels in train_loader:\n",
    "\n",
    "        # forward pass\n",
    "        y_pre = model.forward(feature)\n",
    "        # print(y_pre.shape)\n",
    "        # print(y_train_tensor.shape)\n",
    "\n",
    "        # compute loss\n",
    "        # loss = model.binary_cross_entrophy(y_pre, y_train_tensor)\n",
    "        loss = loss_fn(y_pre, labels)\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # update weights\n",
    "        optim.step()\n",
    "\n",
    "        # clear gradients\n",
    "        optim.zero_grad()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Loss = {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62488250",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f06a277e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9626736044883728\n"
     ]
    }
   ],
   "source": [
    "model.eval() #set model to evaluation mode\n",
    "acc_list=[] # accuracy list\n",
    "with torch.no_grad():\n",
    "    for batch_features,batch_labels in test_loader:\n",
    "\n",
    "        y_pre=model.forward(batch_features)\n",
    "        y_pre=(y_pre>0.5).float() # convert probibilities to binary prediction\n",
    "        acc=(y_pre==batch_labels).float().mean()\n",
    "        acc_list.append(acc)\n",
    "overall_acc=sum(acc_list)/len(acc_list)\n",
    "print(f\"Accuracy : {overall_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d444ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
